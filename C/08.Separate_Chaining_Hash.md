## 08. Hash

---

### 1. 散列表的定义
散列表（Hash Table，又称哈希表）是一种根据关键字**直接访问**内存存储位置的数据结构。

在链表或者有根树等结构中，如果我们知道一个对象的关键字(key)，我们需要与链表或者树中对象的关键字进行逐一比较，从而找到该对象的位置。散列表则不同，它通过将对象的关键字映射为一个地址，将该地址作为对象的存储地址，从而在查找对象时不需要进行关键字的比较。

假设所有关键字在范围`U=[0..n-1]`内，即`U`为关键字的**全域**。函数`h`将关键字的全域`U`映射到散列表`T=[0..m-1]`的**槽位**上：

<img src = "https://img-blog.csdnimg.cn/20190912225601733.png" width = "100%">

**注**：这里散列表的大小`m`一般要比`|U|`小得多。我们可以说一个具有关键字`k`的元素被散列到槽`h(k)`上，也可以说`h(k)`是关键字`k`的散列值。

<img src = "https://img-blog.csdnimg.cn/20190404152055696.png" width = "80%" >

从上图可以看出，散列函数`h`将关键字的全域`U`映射到了`m`个槽内，由于散列表的大小`m`一般要比`|U|`小得多，因此会不可避免的出现多个关键字映射到同一个槽中的现象，如上图中的`k_3`和`k_4`，称这种现象为**冲突**。

为了减少冲突，我们可以**选择一个合适的散列函数**，使得所有的关键字能够均可能均匀的落入所有的槽中。但由于`|U|>m`，因此选择合适的散列函数只能减少冲突，而不能避免冲突。下文中的**链接法**和**开放寻址法**有效的解决冲突。

### 2. 散列函数 
一个好的散列函数应该满足以下特点：

**1. 均匀散列假设**：每个关键字都被等可能地散列到`m`个槽位中的任何一个，并与其他关键字已散列到哪个槽位无关。
**2. 与关键字分布无关**：一种好的方法到处的散列值，在某种程度上应独立于数据可能存在的任何模式。

### 2.1 除法散列法
 除法散列法通过取`k`除以`m`的余数，将关键字`k`映射到`m`个槽中的某一个上，即散列函数为：
 
 <img src = "https://img-blog.csdnimg.cn/201909122256586.png" width = "100%">

由于取余运算的速度很快，因此利用除法散列法计算散列值的速度也是非常快的。

**注**：应用除法散列法时，要避免选择`m`的某些值，例如`m`不应为`2`的幂（当选取`m=2^p`时，`h(k)=k mod 2^p`实际上就是`k`的`p`个最低位数字）。**一个不太接近`2`的整数幂的素数，常常是`m`的一个较好的选择**。

### 2.2 乘法散列法
构造散列函数的乘法散列法包含两个步骤：第一步，用关键字`k`乘上常数`A(0<A<1)`，并提取`kA`的小数部分。第二步，用`m`乘以这个值，再向下取整。

<img src = "https://img-blog.csdnimg.cn/20190912230207187.png" width = "100%">


这里通常选取`m`为2的某个幂次(`m = 2^p`)，使得比较容易用下面的方法实现上述散列函数：

<img src = "https://img-blog.csdnimg.cn/20190404172642930.png" width = "80%" >

**注**：上图中`k`为待散列的关键字，`A`通常取经验值`(√5-1)/2=0.6180339887`。散列值`h(k)`取`k*s`结果中低`w`位`r0`中的高`p`位，其中`p = lg(m)`。下面例子说明了上述方法和直接计算`h(k)`的结果相同。

假设这里取32位整型变量，则`w = 32`，`s = A·2^w≈2654435769`，当取`m = 2^14`计算关键字`k = 123456`的散列值时，首先计算：

<img src = "https://img-blog.csdnimg.cn/20190912230847941.png" width = "100%">

取上述结果中低32位的数据`17612864`的高`p=14`位：

<img src = "https://img-blog.csdnimg.cn/20190912231008290.png" width = "100%">

即通过上述方法计算得到的散列值`h(k)=67`。

此外，直接利用公式也可以计算出关键字`k`的散列值为67。

#### 2.3 全域散列法
为了提高散列函数的平均性能，可以随机地选取散列函数，使之独立于要存储的关键字，这种方法称为**全域散列**。

设$H$为**一组**有限散列函数，它将给定的关键字全域$U$映射到$\{0, 1, ..., m-1\}$中。这样的一个函数组称为**全域的**。

对于每一对不同的关键字$k，l\in U$，满足$h(k)=h(l)$的散列函数$h\in H$的个数至多为$|H|/m$。也就是说，如果从$H$中随机选择一个散列函数，当关键字$k\ne l$时，两者发生冲突的概率不大于$1/m$，这也是从集合$\{0, 1, ..., m-1\}$z中独立地随机选择$h(k)$和$h(l)$时发生冲突的概率。

**设计一个全域散列函数类的过程**如下：
①选择一个足够大的**素数**$p$，使得每一个可能的关键字$k$都落在$[0..p-1]$范围内。
②设$Z_p$表示集合$\{0, 1, ..., p-1\}$，$Z_p^*$表示集合$\{1, 2, ..., p-1\}$。
③对于任何$a\in Z_p^*$和任何$b\in Z_p$，定义散列函数$h_{a, b}$：$$
h_{a, b}(k)=((ak+b)\mod p)\mod m
$$由以上散列函数构成的函数簇为：$$
H_{pm} = \{h_{a, b}:a\in Z_p^*, b\in Z_p\}
$$其中每一个函数$h_{a, b}$都将$Z_p$映射到$Z_m$。
**注**：由于其中要求$p$为素数，因此$m$的选择可以不必是一个素数。可以看出，$H_{pm}$中包含$p(p-1)$个散列函数。

需要值得注意的是，选取散列函数的过程是在每次算法开始运行时进行一次选择，而不是每次计算散列值时都随机选择一个散列函数。当选择好$a$和$b$的值之后，本次算法运行结束之前散列函数保持不变。

## 3. 解决散列值的冲突
前面提及，不同关键字可能被散列函数映射为同一个值，从而产生冲突。常用的解决冲突的方法有**链接法**和**开放寻址法**两种。
### 3.1 链接法
在连接法中，将散列到同一个槽中的所有元素放到一个链表中，因此散列表中的每一个槽中保存着指向一个链表的指针。

<img src = "https://img-blog.csdnimg.cn/20190404200903575.png" width = "80%" >

为了让散列表可以更加快速的对元素进行删除，因此链接法所用的链表应为**双向链表**。

因此，在散列表中查找关键字$k$时步骤如下：

 - ①首先由散列函数$h$计算出散列值$h(k)$。
 - ②然后在散列表中$h(k)$位置中获得链表的头指针。
 - ③最后在链表中查找关键字$k$即可。
### 3.2 链接法性能分析
定义散列表$T$的**装载因子**$\alpha$为$n/m$，即每个链表的平均存储元素数。其中，$n$为存放元素的个数，$m$为散列表的槽位$m$。

链接法散列的**最坏情况**：所有的$n$个关键字都散列到同一个槽中，从而产生出一个长度为$n$的链表。这种情况下，除去计算散列值所需时间，查找一个元素的时间为$\Theta(n)$。

为了分析链接法散列的**平均性能**，首先做如下**简单均匀假设**：假定任何一个给定元素等可能地散列到$m$个槽中的任何一个，且与其他元素被散列到什么位置上无关。

下面分两种情况来分析查找的平均性能：查找不成功和查找成功。

**查找不成功**：假设要查找的元素的关键字为$k$，则根据简单均匀假设可知，关键子$k$每个槽的可能性均为$1/m$，而每个链表的平均长度为$E(L)=n/m=\alpha$，此外假设计算散列值的时间为$O(1)$。因此，查找不成功所需平均时间为：$$\displaystyle O(1)+\sum_{i=0}^{m-1}\frac{1}{m}·L_i=O(1)+\frac{1}{m}\sum_{i=0}^{m-1}L_i=O(1)+\frac{1}{m}·m·E(L)=O(1)+\alpha=\Theta(1+\alpha)$$

**查找成功**：在对元素$x$一次查找成功的情况下，所检查的元素个数为$x$所在链表中$x$前面的元素数+1。此外，在链表中所有在元素$x$之间的元素都是$x$插入之后插入的。因此，为了确定所检查的元素的期望数目，对$x$所在的链表，在$x$之后插入到表中的期望元素数+1，再对表中的$n$个元素$x$取平均。

设$x_i$表示插入到表中的第$i$个元素，$i = 1, 2, ..., n$，并设$k_i=x_i.key$。对关键字$k_i$和$k_j$，定义指示器随机变量$X_{ij}=I\{h(k_i)=h(k_j)\}$。在简单均匀散射的假设下，有$Pr\{h(k_i)=h(k_j)\}=1/m$，因此$E[X_{ij}]=1/m$。于是一次成功查找中，检查元素的期望数目为：$$\begin{aligned}
E[\frac{1}{n}\sum_{i = 1}^{n}(1+\sum_{j = i + 1}^{n}X_{ij})]&=\frac{1}{n}\sum_{i=1}^{n}(1+\sum_{j = i + 1}^{n}E[X_{ij}])
\\ &=\frac{1}{n}\sum_{i = 1}^{n}(1+\sum_{j = i + 1}^{n}\frac{1}{m})=1+\frac{1}{mn}\sum_{i = 1}^{n}(n-i)
\\ &=1+\frac{1}{mn}(\sum_{i=1}^{n}n-\sum_{i=1}^{n}i)=1+\frac{1}{mn}(n^2-\frac{n(n+1}{2})
\\ &=1+\frac{n-1}{2m}=1+\alpha/2-\alpha/2n
\end{aligned}
$$因此一次查找成功的总时间为$\Theta(2+\alpha/2-\alpha/2n)=\Theta(1+\alpha)$。

如果散列表中的槽数与表中的元素数成正比，即$n = O(m)$，则$\alpha = n/m=O(m)/m=O(1)$。因此在平均情况下，利用链接法解决冲突时，如果散列表中的槽数与表中的元素数成正比，则一次查找所需时间为$O(1)$。

### 3.3 开放寻址法
开放寻址法将所有的元素都放在散列表中。它不用存储指针因而可以用与链接法同样的空间来提供更多的槽，潜在地减少了冲突，提高了检索速度。

由于开放寻址法的所有元素都存储在散列表中，因此散列表的槽数$m$大于元素的个数$n$,使得装载因子$\alpha<1$。

为了使用开放寻址法在散列表中插入一个元素，需要连续地检查散列表，或称为**探查**，直到找到一个空槽来放置待插入的关键字为止。

<img src = "https://img-blog.csdnimg.cn/20190404220343165.png" width="80%">

上例中关键字$k$通过散列函数$h$计算出的槽位在散列表中已经被占用，且该位置后面两个位置均已被占用，因此需要连续地进行三次探查才能够将关键字为$k$的元素插入散列表。

当然，**探查的顺序不一定是顺序的**，为了确定要探查哪些槽，将散列函数进行扩充，使之包含探查号以作为其第二个输入参数。这样，散列函数就变为：$$h:U×\{0, 1, ..., m-1\}\rightarrow \{0, 1, ..., m-1\}
$$对于每一个关键字$k$，使用开放寻址法的探查序列为：$$<h(k, 0),h(k, 1),...,h(k, m-1)>$$
**注**：它是$<0, 1, ..., m-1>$的一个排列，使得当散列表逐渐填满时，每一个表位最终都可以被考虑为用来插入关键字的槽。

因此，向散列表中插入元素的伪代码如下：

```
HASH_INSERT(T, k)
	i = 0
	repeat
		j = h(k, i)
		if T[j] == NIL
			T[j] = k
			return j
		else i = i + 1
	until i == m
	error "hash_table overflow"
```
同样，查找关键字的伪代码如下：

```
HASH_SEARCH(T, k)
	i = 0
	repeat
		j = h(k, i)
		if T[j] == k
			return j
		i = i + 1
	until T[j] == NIL or i == m
	return NIL
```
值得注意的是，上述代码的前提是之前插入的元素不会被删除。因为如果被删除的位置是其他某个元素探查过程中的中间槽，则当探查到该槽时，会误以为该槽的值为NIL，从而结束查找，导致查找不成功。

解决这个问题的方法是将被删除的元素的槽标记为DETECTED，从而在其他元素在插入或者查找时对该槽增加一些处理即可。但是，当使用特殊值DETECTED时，查找时间就不再依赖于装载因此$\alpha$了。因此，**在必须删除关键字的应用中，更常见的做法是使用链接法来解决冲突**。

下面介绍三种方法来计算开放寻址法中的探查序列`<h(k, 0),h(k, 1),...,h(k, m-1)>`：

**①线性探查**
线性探查方法采用的散列函数为：$$h(k, i) = (h'(k)+i)\mod m， i= 0, 1, ..., m-1
$$其中，$h'：U\rightarrow\{0, 1, ..., m-1\}$是一个**辅助散列函数**。

从散列函数的形式可以看出，由该散列函数计算出的探查序列为：$$<T[h'(k)], T[h'(k)+1],...,T[m-1], T[0], T[1], ...T[h'(k)-1]>$$

线性探查方法虽然容易实现，但其存在**一次集群**的问题。随着连续被占用的槽不断增加，平均查找时间也随之不断增加。（当一个空槽前有$i$个满的槽时，则关键字$k$被映射到这$i$个槽的概率为$i·(1/m)=i/m$，可得该空槽为下一个被占用的概率为$i/m+1/m=(i+1)/m$。因此，连续被占用的槽就会变得越来越长，因而平均查找时间也会越来越长。）

**②二次探查**
二次探查所采用的散列函数形式如下：$$h(k, i)=(h'(k)+c_ii+c_2i^2)\mod m，     i= 0, 1, ..., m-1
$$其中，$h'$是辅助散列函数，$c_1$和$c_2$为正的辅助常量。
**注**：如果两个关键字的初始探查位置相同，那么它们的探查序列也是相同的，因为$h(k_1, 0)=h(k_2, 0)$蕴含着$h(k_1, i)=h(k_2, i)$。这会导致一种轻度的集群，称为**二次集群**。

**③双重散列**
双重散列是用于开放寻址法的最好方法之一，因为它所产生的排列具有随机选择排列的许多特性。
双重散列采用如下形式的散列函数：$$h(k, i)=(h_1(k)+ih_2(k))\mod m，     i= 0, 1, ..., m-1
$$其中，$h_1$和$h_2$均为辅助散列函数。

双重散射的初始探查位置为$T[h_1(k)]$，后续的探查位置是前一个位置加上偏移量$h_2(k)$模$m$。因此，这里的探查序列以两种不同方式依赖于关键字$k$，因为初始探查位置、偏移量或者二者都可能发生变化。

**注**：**为了能查找整个散列表，值$h_(k)$必须要与表的大小$m$互素**。

下面列举两种方法来满足上述条件：
①取$m$为2的幂，并设计一个总产生奇数的$h_2$。
②取$m$为素数，并设计一个总是返回较$m$小的正整数的函数$h_2$。如：取$m$为素数，并取$$h_1(k)=k\mod m, \space\space h_2(k)=1+(k\mod m')
$$其中$m'$略小于$m$。
例如：$k = 123456, m=701, m'=700$，则有$h_1(k)=80, h_2(k)=257$。于是第一个探查位置为80，然后按每次递增257个槽（模$m$）的序列进行探查，直到探查结束。
